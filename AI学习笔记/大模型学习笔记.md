# 大模型学习笔记

## 1、使用langchain简单调用llm

```pyton
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain.prompts.chat import ChatPromptTemplate, ChatPromptValue
from langchain_community.utilities import SearchApiAPIWrapper
from langchain_core.tools import Tool

if __name__ == "__main__":
    
    # 模型
    llm = ChatOpenAI(
        temperature=0.0,
        api_key='sk-0EXfWLim00ftiVLDVwMmotZOgSPi0aphLqXSBxefeIhoh44y',
        base_url='https://api.chatanywhere.tech',
        streaming=True
        )

    # 模板
    chat_prompt = ChatPromptTemplate.from_messages([
        ("system", "你是一名聊天助手，你的名字叫阿giao,每次开头都要以`一giao我类giao开头`，并且时不时的说一句`火花`"),
        ("human", "{text}"),
    ])

    # 输出解析器
    output_parser = StrOutputParser()

    
    # 管道
    chain = chat_prompt | llm | output_parser  # 三阶段管道

    # while True:
    #     # 直接传递用户输入字典（自动触发模板渲染）
    #     print(chain.invoke({"text":  input("请输入:")}))
    
    while True:
        user_input = input("\n请输入:")
        print("阿giao：", end="", flush=True)  # 🌟 流式输出前置符 
        
        # 🌟 流式响应核心代码 
        for chunk in chain.stream({"text":  user_input}):
            print(chunk, end="", flush=True)  # 逐块输出 
        print()  # 换行分隔 
```

## 2、文档加载器

```
# from langchain_community.document_loaders.csv_loader import CSVLoader

# 从csv文件中加载文件
# loader = CSVLoader('./file/random_data.csv', encoding='utf-8')
# data = loader.load()
# print(data)


# 从目录中加载文档
from langchain_community.document_loaders import DirectoryLoader
loader = DirectoryLoader("./file")
docs = loader.load()
print(docs)

```



## 3、embedding(嵌入)

### 1、embedding APi调用

```
from langchain_openai import OpenAIEmbeddings

#  ChatOpenAI(
#         temperature=0.0,
#         api_key='sk-0EXfWLim00ftiVLDVwMmotZOgSPi0aphLqXSBxefeIhoh44y',
#         base_url='https://api.chatanywhere.tech',
#         streaming=True
#         )

embeddings = OpenAIEmbeddings(
                                model="text-embedding-3-large", 
                                api_key="sk-0EXfWLim00ftiVLDVwMmotZOgSPi0aphLqXSBxefeIhoh44y",
                                base_url='https://api.chatanywhere.tech'
                            )

aa = embeddings.embed_query("Hello, world!")
bb = embeddings.embed_query("""本文共4万字，建议收藏阅读
本文主要为当前大模型领域热门研究方向（如文生图、文生视频、文生音乐等）的热门论文。希望能够为大家提供较为全面的大模型最新研究进展。当然，目前还无法涵盖所有热门论文以及研究方向，望请见谅。
以下，为2024年2月份收录的一些热门大模型研究论文。文章篇幅较长，共计4万字，建议收藏～"""
)


print(len(aa))
print(len(bb))
```

### 2、将词向量存储到redis中

```
# 从csv中加载内容
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Redis

loader = CSVLoader('./file/random_data.csv', encoding='utf-8')
documents = loader.load()

# 调用分词api将分词后的内容保存到redis中


embeddings = OpenAIEmbeddings(
                                model="text-embedding-3-large", 
                                api_key="sk-0EXfWLim00ftiVLDVwMmotZOgSPi0aphLqXSBxefeIhoh44y",
                                base_url='https://api.chatanywhere.tech'
                            )

# 3. 连接到Redis（请修改为您的配置）
REDIS_URL = "redis://localhost:6379"

# 4. 将文档存入Redis向量数据库
vectorstore = Redis.from_documents(
    documents=documents,
    embedding=embeddings,
    redis_url=REDIS_URL,
    index_name="csv_data",
    index_schema={
        "text": [{"name": "content"}],

        "vector": [{"name": "content_vector", "dims": 3072, "algorithm": "HNSW"}]
    }
)

print("数据成功存入Redis，索引名称：", vectorstore.index_name)



# if __name__ == "__main__":
#     # 查询测试
#     results = vectorstore.similarity_search("陈秀英", k=3)
#     print("相似结果：", results)
```

## 4、基于redis词向量数据库的简单聊天机器人

```

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Redis
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate


# 初始化embedding模型（需要与存储时一致）
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-large",
    api_key="sk-0EXfWLim00ftiVLDVwMmotZOgSPi0aphLqXSBxefeIhoh44y",
    base_url='https://api.chatanywhere.tech'
)


# 初始化大语言模型
llm = ChatOpenAI(
        temperature=0.0,
        api_key='sk-0EXfWLim00ftiVLDVwMmotZOgSPi0aphLqXSBxefeIhoh44y',
        base_url='https://api.chatanywhere.tech',
        streaming=True
        )

# Redis连接配置（需与存储时一致）
REDIS_URL = "redis://localhost:6379"
INDEX_NAME = "csv_data"

# 连接到已存在的Redis向量库
vectorstore = Redis(
    redis_url=REDIS_URL,
    index_name=INDEX_NAME,
    embedding=embeddings
)

# 自定义提示模板
PROMPT_TEMPLATE = """请根据以下上下文信息回答问题。
如果你不知道答案或上下文信息不足，请如实回答你不知道。
上下文：{context}
问题：{question}
请用中文提供清晰、简洁的回答："""


# 创建检索增强生成链
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
    chain_type_kwargs={
        "prompt": PromptTemplate(
            template=PROMPT_TEMPLATE,
            input_variables=["context", "question"]
        )
    },
    return_source_documents=True
)

def chat_interface():
    print("数据库聊天机器人已启动！输入'exit'退出")
    while True:
        query = input("\n你的问题：")
        if query.lower() == "exit":
            print("再见！")
            break
        
        try:
            # 执行查询
            result = qa_chain.invoke({"query": query})
            
            # 显示回答
            print("\n回答：", result["result"])
            
                
        except Exception as e:
            print("出错了，请稍后再试。错误信息：", str(e))
            
            
if __name__ == "__main__":
    # # 相似度查询测试
    # query = "秀英的信息是什么"
    # results = vectorstore.similarity_search(query, k=5)
    
    # print(f"与'{query}'相似的结果：")
    # for i, doc in enumerate(results):
    #     print(f"\n结果 {i+1}:")
    #     print(f"内容: {doc.page_content}")
    #     print(f"元数据: {doc.metadata}")
    chat_interface()
```

